{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find cheap stock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lfu7\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas_datareader\\compat\\__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_frame_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasted weekday: 2020-06-08 19:21:55.069693\n",
      "Total number:  505\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import calendar\n",
    "import datetime as dt\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import yfinance as yf\n",
    "import bs4 as bs\n",
    "import pickle\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm # progress\n",
    "\n",
    "style.use('ggplot')\n",
    "mpl.rcParams['figure.figsize'] = (16.0, 9.0)\n",
    "mpl.rcParams['font.size'] = 12\n",
    "mpl.rcParams['legend.fontsize'] = 'large'\n",
    "mpl.rcParams['figure.titlesize'] = 'medium'\n",
    "\n",
    "def prev_weekday(adate):\n",
    "    # adate -= dt.timedelta(days=1)\n",
    "    while adate.weekday() > 4: # Mon-Fri are 0-4\n",
    "        adate -= dt.timedelta(days=1)\n",
    "    return adate\n",
    "\n",
    "date_start = prev_weekday(dt.datetime(2015, 1, 6))\n",
    "date2 = dt.datetime(2020, 2, 19)\n",
    "date_end = prev_weekday(dt.datetime.now())\n",
    "\n",
    "print('Lasted weekday:', date_end)\n",
    "      \n",
    "def save_sp500_tickers():\n",
    "    resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "    tickers = []\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[0].text\n",
    "        tickers.append(ticker.rstrip().replace('.', '-'))\n",
    "        \n",
    "#     with open(\"sp500tickers.pickle\",\"wb\") as f:\n",
    "#         pickle.dump(tickers,f)\n",
    "        \n",
    "    print('Total number: ', len(tickers))\n",
    "    return tickers\n",
    "            \n",
    "tickers = save_sp500_tickers()[:]\n",
    "today_price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compile_data(tickers = tickers, avg_period = 7):\n",
    "\n",
    "    dDay = 7\n",
    "    anomaly = []\n",
    "    main_df = pd.DataFrame()\n",
    "    shiftDay = dt.timedelta(days=dDay)\n",
    "\n",
    "    for count, ticker in enumerate(tqdm(tickers[:])):\n",
    "        print(count, ': ', ticker)\n",
    "        \n",
    "        # Download stock data at 3 periods\n",
    "        data1 = yf.download(ticker, start=date_start-shiftDay, end=date_start+shiftDay)\n",
    "        data2 = yf.download(ticker, start=date2-shiftDay, end=date2+shiftDay)\n",
    "        data3 = yf.download(ticker, start=date_end-shiftDay, end=date_end+shiftDay)\n",
    "        \n",
    "        # if Data was not availble, exit\n",
    "        if data1.empty or data2.empty or data3.empty:\n",
    "            anomaly.append(ticker)\n",
    "            continue\n",
    "        \n",
    "#         time.sleep(0.5)\n",
    "#         data1 = web.DataReader(ticker, 'yahoo', date_start, date_start)\n",
    "#         data2 = web.DataReader(ticker, 'yahoo', date2, date2)\n",
    "#         data3 = web.DataReader(ticker, 'yahoo', date_end, date_end)\n",
    "        \n",
    "        if avg_period:\n",
    "            data1['Adj Close'] = data1['Adj Close'].rolling(window=avg_period, min_periods=0).mean()\n",
    "            data2['Adj Close'] = data2['Adj Close'].rolling(window=avg_period, min_periods=0).mean()\n",
    "            data3['Adj Close'] = data3['Adj Close'].rolling(window=avg_period, min_periods=0).mean()\n",
    "            data1.dropna(inplace=True)\n",
    "            data2.dropna(inplace=True)\n",
    "            data3.dropna(inplace=True)\n",
    "            mid = len(data1.index) // 2\n",
    "            data = pd.concat([data1.iloc[[mid], :], data2.iloc[[mid], :], data3.iloc[[-1], :]])\n",
    "        else:\n",
    "            data = pd.concat([data1.tail(1), data2.tail(1), data3.tail(1)])\n",
    "        \n",
    "#         print(count, ticker, data)\n",
    "        \n",
    "        # get the adjust close price and volume on the last day\n",
    "        volume = pd.DataFrame(data3['Volume'].tail(1))\n",
    "        data = pd.DataFrame(data['Adj Close'])\n",
    "        \n",
    "        # reindex and transpose\n",
    "        volume.reset_index(drop=True, inplace=True)\n",
    "        volume.rename(columns={'Volume': ticker}, inplace=True)\n",
    "        volume['Volume'] = 'Volume'\n",
    "        volume.set_index([\"Volume\"], inplace=True)\n",
    "        volume = volume.T\n",
    "        data.rename(columns={'Adj Close': ticker}, inplace=True)\n",
    "        \n",
    "        df = data.T\n",
    "\n",
    "        # Check null values\n",
    "        if len(df.columns) < 3 or df.isnull().values.any():\n",
    "            anomaly.append(ticker)\n",
    "            continue\n",
    "        \n",
    "        # Rename the Date Column to avoid different date \n",
    "        df.rename(columns={df.columns[0]:df.columns[0].strftime(\"%Y-%m\")}, inplace=True, errors=\"raise\")\n",
    "        df.rename(columns={df.columns[1]:df.columns[1].strftime(\"%Y-%m\")}, inplace=True, errors=\"raise\")\n",
    "        df.rename(columns={df.columns[2]:df.columns[2].strftime(\"%Y-%m\")}, inplace=True, errors=\"raise\")\n",
    "\n",
    "        # add volumen and sector column\n",
    "        df = df.join(volume, how='outer')\n",
    "        \n",
    "        try:\n",
    "            stockInfo = yf.Ticker(ticker).info\n",
    "            df['Sector'] = [stockInfo['sector']]\n",
    "            df['Industry'] = [stockInfo['industry']]\n",
    "        except:\n",
    "            df['Sector'] = df['Industry'] = None      \n",
    " \n",
    "        if main_df.empty:\n",
    "            main_df = pd.DataFrame(data=df)\n",
    "        else:    \n",
    "            main_df = main_df.append(df)\n",
    "            \n",
    "    main_df.index.name = 'Ticker'\n",
    "    return main_df, anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, anomaly= compile_data()\n",
    "print('Number of anomalous tickers:', len(anomaly))\n",
    "if len(anomaly):\n",
    "    print('Anomalous tickers:', anomaly)\n",
    "\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          2015-01    2020-02  2020-06       Volume              Sector  \\\n",
      "Ticker                                                                   \n",
      "NCLH    46.392000  52.762000   18.936  109330900.0   Consumer Cyclical   \n",
      "OXY     60.675123  40.803529   16.070  118124800.0              Energy   \n",
      "COTY    17.661850  11.507415    4.650   32658500.0  Consumer Defensive   \n",
      "CCL     38.579615  42.725340   18.182  113177600.0                None   \n",
      "UAL     66.002000  80.479999   34.906  135203900.0                None   \n",
      "\n",
      "                             Industry    Ratio1    Ratio2   Ratio12  \n",
      "Ticker                                                               \n",
      "NCLH                  Travel Services  1.137308  0.358895  3.168919  \n",
      "OXY                     Oil & Gas E&P  0.672492  0.393838  1.707532  \n",
      "COTY    Household & Personal Products  0.651541  0.404087  1.612376  \n",
      "CCL                              None  1.107459  0.425555  2.602385  \n",
      "UAL                              None  1.219357  0.433723  2.811375  \n"
     ]
    }
   ],
   "source": [
    "# print(yf.Ticker(\"AAPL\").info)\n",
    "# print(yf.Ticker(\"MMM\").info['sector'])\n",
    "\n",
    "df['Ratio1'] = df.iloc[:, 1] / df.iloc[:, 0]\n",
    "df['Ratio2'] = df.iloc[:, 2] / df.iloc[:, 1]\n",
    "df['Ratio12'] = df['Ratio1'] / df['Ratio2']\n",
    "df_sort = df.sort_values(by=['Ratio2', 'Ratio1'], ascending=[True, False])\n",
    "\n",
    "print(df_sort.head())\n",
    "\n",
    "# if not os.path.exists('sp500_bargain.csv'):\n",
    "df_sort.to_csv('sp500_bargain.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of All Tickers\n",
    "### Method 1\n",
    "\n",
    "https://pypi.org/project/get-all-tickers/\n",
    "\n",
    "### Method 2\n",
    "\n",
    "Another more complete way:\n",
    "\n",
    "https://pypi.org/project/Yahoo-ticker-downloader/\n",
    "\n",
    "https://github.com/Benny-/Yahoo-ticker-symbol-downloader\n",
    "\n",
    ">`YahooTickerDownloader.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6372\n"
     ]
    }
   ],
   "source": [
    "from get_all_tickers import get_tickers as gt\n",
    "\n",
    "list_of_tickers = gt.get_tickers()\n",
    "# # or if you want to save them to a CSV file\n",
    "# get.save_tickers()\n",
    "\n",
    "print(len(list_of_tickers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:13<00:00,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          2020-02  2020-06-08 19:22:06.121972   Volume       Sector  \\\n",
      "Ticker                                                                \n",
      "GMBL     5.825000                        6.52   811271         None   \n",
      "ADXN    11.300000                        7.28        0                \n",
      "ADT      7.007494                        8.53  3049096  Industrials   \n",
      "ALTG    10.281800                        8.06   135064         None   \n",
      "BPYPN   24.706290                       20.17    76548  Real Estate   \n",
      "\n",
      "                              Industry  Ratio1 in 5 yr  Ratio2 since Feb  \n",
      "Ticker                                                                    \n",
      "GMBL                              None        0.019205          1.119313  \n",
      "ADXN                                          1.000000          0.644248  \n",
      "ADT     Security & Protection Services        0.376004          1.217268  \n",
      "ALTG                              None        1.652230          0.783909  \n",
      "BPYPN             Real Estate Services        1.000009          0.816391  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = '../data/all_stock'\n",
    "date_end = prev_weekday(dt.datetime.now())\n",
    "\n",
    "def compile_data_all(tickers = tickers, avg_period = 7, get_sector_info = True):\n",
    "\n",
    "    dDay = 7\n",
    "    anomaly = []\n",
    "    main_df = pd.DataFrame()\n",
    "    shiftDay = dt.timedelta(days=dDay)\n",
    "\n",
    "    for count, ticker in enumerate(tqdm(tickers[:])):\n",
    "#         print(count, '. ', ticker)\n",
    "        \n",
    "        ticker = ticker.lstrip().rstrip().replace('~', '').replace('$', '')\n",
    "        \n",
    "        useLocalData = os.path.exists(data_path+'/{}.csv'.format(ticker))\n",
    "\n",
    "        if useLocalData:\n",
    "#             print('Retrieve data from '+data_path+'/{}.csv'.format(ticker))\n",
    "            df = pd.read_csv(data_path+'/{}.csv'.format(ticker))\n",
    "        else:\n",
    "            print(ticker, ' does not exist! Skip...')\n",
    "            anomaly.append(ticker)\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            data3 = web.DataReader(ticker, 'yahoo', date_end-shiftDay, date_end)\n",
    "            data3.drop(['Open', 'High', 'Low', 'Close'], 1, inplace=True)\n",
    "        except:\n",
    "            print(ticker, 'No data fetched for', ticker, 'using YahooDailyReader')\n",
    "            anomaly.append(ticker)\n",
    "            continue\n",
    "            \n",
    "        df.set_index(\"Date\", inplace=True)\n",
    "        df.index = pd.to_datetime(df.index, format='%Y-%m-%d')\n",
    "                \n",
    "        df = df.loc[(date_start-shiftDay):, :].copy()\n",
    "        \n",
    "        # Download stock data at 3 periods\n",
    "        data1 = df.iloc[:(2*dDay+1), :].copy()\n",
    "        data2 = df.loc[(date2-shiftDay):(date2+shiftDay), :].copy()\n",
    "#         data3 = df.loc[(date_end-shiftDay):, :].copy()\n",
    "\n",
    "        \n",
    "        # if Data was not availble, exit\n",
    "        if data1.empty or data2.empty or data3.empty:\n",
    "            anomaly.append(ticker)\n",
    "            continue\n",
    "        \n",
    "        if avg_period:\n",
    "            data1['Adj Close'] = data1['Adj Close'].rolling(window=avg_period, min_periods=0).mean()\n",
    "            data2['Adj Close'] = data2['Adj Close'].rolling(window=avg_period, min_periods=0).mean()\n",
    "#             data3['Adj Close'] = data3['Adj Close'].rolling(window=avg_period, min_periods=0).mean()\n",
    "            data1.dropna(inplace=True)\n",
    "            data2.dropna(inplace=True)\n",
    "            data3.dropna(inplace=True)\n",
    "            mid = (len(data2.index)-1) // 2\n",
    "#             print(mid, len(data1.index), len(data2.index), len(data3.index))\n",
    "            data = pd.concat([data1.iloc[[mid], :], data2.iloc[[mid+1], :], data3.iloc[[-1], :]])\n",
    "        else:\n",
    "            data = pd.concat([data1.tail(1), data2.tail(1), data3.tail(1)])\n",
    "        \n",
    "#         print(count, ticker, data)\n",
    "        \n",
    "        # get the adjust close price and volume on the last day\n",
    "        volume = pd.DataFrame(data3['Volume'].tail(1))\n",
    "        data = pd.DataFrame(data['Adj Close'])\n",
    "        \n",
    "        # reindex and transpose\n",
    "        volume.reset_index(drop=True, inplace=True)\n",
    "        volume.rename(columns={'Volume': ticker}, inplace=True)\n",
    "        volume['Volume'] = 'Volume'\n",
    "        volume.set_index([\"Volume\"], inplace=True)\n",
    "        volume = volume.T\n",
    "        data.rename(columns={'Adj Close': ticker}, inplace=True)\n",
    "        \n",
    "        df = data.T\n",
    "\n",
    "        # Check null values\n",
    "        if len(df.columns) < 3 or df.isnull().values.any():\n",
    "            anomaly.append(ticker)\n",
    "            continue\n",
    "        \n",
    "        # Rename the Date Column to avoid different date \n",
    "#         df.rename(columns={df.columns[0]:df.columns[0].strftime(\"%Y-%m\")}, inplace=True, errors=\"raise\")\n",
    "        df.rename(columns={df.columns[1]:df.columns[1].strftime(\"%Y-%m\")}, inplace=True, errors=\"raise\")\n",
    "        df.rename(columns={df.columns[2]:date_end}, inplace=True, errors=\"raise\")\n",
    "#         df.rename(columns={df.columns[2]:df.columns[2].strftime(\"%Y-%m-%d\")}, inplace=True, errors=\"raise\")\n",
    "        \n",
    "        # add volume and sector column\n",
    "        df = df.join(volume, how='outer')\n",
    "        \n",
    "        if get_sector_info:\n",
    "            try:\n",
    "                stockInfo = yf.Ticker(ticker).info\n",
    "                df['Sector'] = [stockInfo['sector']]\n",
    "                df['Industry'] = [stockInfo['industry']]\n",
    "            except:\n",
    "                df['Sector'] = df['Industry'] = None      \n",
    "\n",
    "        # Add ratio\n",
    "        years = (date2 - df.columns.values[0]).days / 365\n",
    "        if years < 1e-2:\n",
    "            years = 1e3 \n",
    "        df['Ratio1 in 5 yr'] = (df.iloc[:, 1] / df.iloc[:, 0]).pow(5 / years)\n",
    "        df['Ratio2 since Feb'] = df.iloc[:, 2] / df.iloc[:, 1]\n",
    "        \n",
    "        df.drop([df.columns.values[0]], 1, inplace=True)\n",
    "                \n",
    "        if main_df.empty:\n",
    "            main_df = pd.DataFrame(data=df)\n",
    "        else:    \n",
    "            main_df = main_df.append(df)\n",
    "            \n",
    "    main_df.index.name = 'Ticker'\n",
    "    return main_df, anomaly\n",
    "\n",
    "df_all, anomaly_all = compile_data_all(['GMBL', 'ADXN', 'ADT', 'ALTG', 'BPYPN'])\n",
    "print(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                             | 56/6372 [02:33<4:53:58,  2.79s/it]"
     ]
    }
   ],
   "source": [
    "sector_info = False \n",
    "\n",
    "df_all, anomaly_all = compile_data_all(list_of_tickers, get_sector_info=sector_info)\n",
    "print('Number of anomalous tickers:', len(anomaly_all))\n",
    "if len(anomaly_all):\n",
    "    print('Anomalous tickers:', anomaly_all)\n",
    "\n",
    "print(df_all.head())\n",
    "\n",
    "df_all['Ratio1/Ratio2'] = df_all['Ratio1 in 5 yr'] / df_all['Ratio2 since Feb']\n",
    "\n",
    "if sector_info:\n",
    "    df_all_sort = df_all.sort_values(by=['Sector', 'Ratio2 since Feb', 'Ratio1 in 5 yr'], ascending=[True, True, False])\n",
    "else:\n",
    "    df_all_sort = df_all.sort_values(by=['Ratio2 since Feb', 'Ratio1 in 5 yr'], ascending=[True, False])\n",
    "\n",
    "print(df_all_sort.head())\n",
    "\n",
    "# if not os.path.exists('sp500_bargain.csv'):\n",
    "if sector_info:\n",
    "    df_all_sort.to_csv('./all_bargain_sectorInfo.csv')\n",
    "else:\n",
    "    df_all_sort.to_csv('./all_bargain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add sector to csv\n",
    "df_all2 = pd.read_csv('./all_bargain.csv')\n",
    "\n",
    "sector = [None] * len(df_all2.index)\n",
    "industry = [None] * len(df_all2.index)\n",
    "\n",
    "for i, ticker in enumerate(tqdm(list(df_all2['Ticker']))):\n",
    "   \n",
    "    try:\n",
    "        stockInfo = yf.Ticker(ticker).info\n",
    "        sector[i] = stockInfo['sector']\n",
    "        industry[i] = stockInfo['industry']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(sector, industry)\n",
    "\n",
    "df_all2['Sector'] = sector\n",
    "df_all2['Industry'] = industry\n",
    "        \n",
    "df_all_sort2 = df_all2.sort_values(by=['Sector', 'Ratio2 since Feb', 'Ratio1 in 5 yr'], ascending=[True, True, False])\n",
    "\n",
    "print(df_all_sort2.head())\n",
    "\n",
    "df_all_sort2.to_csv('./all_bargain_sectorInfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tickers = ['AAPL', 'XOM']\n",
    "prevWeek = dt.timedelta(days=3)\n",
    "\n",
    "# Download stock data at 3 periods\n",
    "data1 = yf.download(tickers, start=date_start-prevWeek, end=date_start)\n",
    "data2 = yf.download(tickers, start=date2-prevWeek, end=date2)\n",
    "data3 = yf.download(tickers, start=date_end-prevWeek, end=date_end)\n",
    "\n",
    "# get the adjust close price and volume on the last day\n",
    "adjClose_col = [name[0] in ['Adj Close'] for name in data1.columns]\n",
    "volume_col = [name[0] in ['Volume'] for name in data3.columns]\n",
    "volume = data3[data3.columns[volume_col]].tail(1)\n",
    "data1 = data1[data1.columns[adjClose_col]].tail(1)\n",
    "data2 = data2[data2.columns[adjClose_col]].tail(1)\n",
    "data3 = data3[data3.columns[adjClose_col]].tail(1)\n",
    "\n",
    "# prcess volume\n",
    "volume.columns = [x[1] for x in volume.columns]\n",
    "volume.reset_index(drop=True, inplace=True)\n",
    "volume['Volume'] = 'Volume'\n",
    "volume.set_index([\"Volume\"], inplace=True)\n",
    "volume = volume.T\n",
    "\n",
    "# combine price and volume and transpose\n",
    "df = pd.concat([data1, data2, data3]).T\n",
    "df.index = [x[1] for x in df.index]\n",
    "df = df.join(volume, how='outer')\n",
    "df.index.name = 'Ticker'\n",
    "print(df, df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(), df.info(), df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_data(tickers):\n",
    "\n",
    "    main_df = pd.DataFrame()\n",
    "    df = pd.DataFrame()\n",
    "    prevWeek = dt.timedelta(days=7)\n",
    "\n",
    "    for count, ticker in enumerate(tickers): ## tickers)):\n",
    "        data1 = yf.download(ticker, start=date_start-prevWeek, end=date_start, group_by = 'ticker')\n",
    "        data2 = yf.download(ticker, start=date2-prevWeek, end=date2)\n",
    "        data3 = yf.download(ticker, start=date_end-prevWeek, end=date_end)\n",
    "#         df.set_index('Date', inplace=True)\n",
    "\n",
    "        data1 = data1['Adj Close'].tail(1)\n",
    "        data2 = data2['Adj Close'].tail(1)\n",
    "        data3 = data3['Adj Close'].tail(1)\n",
    "        \n",
    "#         print(data1)\n",
    "        df = pd.concat([data1, data2, data3])\n",
    "        df.rename(ticker, inplace=True) \n",
    "#         print(df, type(df))\n",
    "    \n",
    "        if main_df.empty:\n",
    "            main_df = pd.DataFrame(data=df).T\n",
    "        else:    \n",
    "            main_df = main_df.append(df)\n",
    "            \n",
    "    main_df.index.name = 'Ticker'\n",
    "    return main_df\n",
    "    \n",
    "compile_data(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol in ['AAPL', 'XOM']:\n",
    "    symbol = symbol.replace('.', '-')\n",
    "    company = yf.Ticker(symbol)\n",
    "    df = company.history(period=\"7d\")\n",
    "    df.dropna(inplace=True)\n",
    "    today_price.append(df.iloc[-1, df.columns.get_loc('Close')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "today_price = []\n",
    "\n",
    "for symbol in list(final_df['symbol']):\n",
    "    symbol = symbol.replace('.', '-')\n",
    "    company = yf.Ticker(symbol)\n",
    "    df2 = company.history(period=\"7d\")\n",
    "    df2.dropna(inplace=True)\n",
    "    today_price.append(df2.iloc[-1, df2.columns.get_loc('Close')])\n",
    "\n",
    "final_df['Today_Price'] = today_price\n",
    "final_df['Dividend_Perc'] = final_df['dividend_Rate'] / final_df['Today_Price'] * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output all stocks that dividend > threshold\n",
    "threshold = 0.8\n",
    "print(final_df[final_df['Dividend_Perc'] >= threshold])\n",
    "# final_df[final_df['Dividend_Perc'] >= threshold].to_csv('stock_dividend.csv')\n",
    "final_df[final_df['Dividend_Perc'] >= threshold].to_csv('stock_dividend_{}.csv'.format(day_today))\n",
    "\n",
    "\n",
    "plt.plot(final_df['Dividend_Perc'], color='blue')\n",
    "plt.plot(final_df.index, [1]*len(final_df.index), color='green', alpha=0.25)\n",
    "plt.ylim([0, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = dt.datetime(year, month, 1)\n",
    "end = dt.datetime.now()\n",
    "start = end - dt.timedelta(days=7)\n",
    "today_price = []\n",
    "\n",
    "for symbol in list(final_df['symbol']):\n",
    "    symbol = symbol.replace('.', '-')\n",
    "    df2 = web.DataReader(symbol, 'yahoo', start, end)\n",
    "    df2.reset_index(inplace=True)\n",
    "    df2.set_index(\"Date\", inplace=True)\n",
    "    today_price.append(df2.iloc[-1, df2.columns.get_loc('Adj Close')])\n",
    "    \n",
    "# print(len(final_df.index), len(today_price))\n",
    "# print(today_price)\n",
    "final_df['Today_Price'] = today_price\n",
    "    \n",
    "print(final_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(final_df['dividend_Rate'] / final_df['Today_Price'] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
